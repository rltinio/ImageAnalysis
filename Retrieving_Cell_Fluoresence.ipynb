{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/raphaeltinio/Lab Analysis MAC/ImageAnalysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "print(f\"Current Working Directory: {current_directory}\")\n",
    "\n",
    "from Tusc5ImageUtils import *\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from skimage import exposure\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "from cellpose import utils, io, plot, models, denoise\n",
    "from scipy.ndimage import binary_erosion, binary_fill_holes, center_of_mass\n",
    "from scipy.signal import find_peaks\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nd2\n",
    "from skimage.measure import regionprops\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Directory Configuration ###\n",
    "\n",
    "'''\n",
    "Input name of folder with .nd2 files in the parent directory of this python notebook\n",
    "'''\n",
    "\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "target_folder_name = #INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Fluoresence Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ".nd2 files with flipped top and bottom for whatever reason\n",
    "'''\n",
    "backward_files = ['3604R_GLUT1_WGA_0001.nd2',\n",
    "                  '3604R_GLUT1_WGA_0003.nd2',\n",
    "                  '3654L_GLUT1_WGA_0001.nd2',\n",
    "                  '3654L_GLUT1_WGA_0003.nd2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set the min and max for the DAPI projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3608R_GLUT1_WGA_0002.nd2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m f \u001b[38;5;241m=\u001b[39m nd2\u001b[38;5;241m.\u001b[39mND2File(nd2_path)\n\u001b[1;32m     24\u001b[0m z_sep \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mvoxel_size()\u001b[38;5;241m.\u001b[39mz\n\u001b[0;32m---> 25\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mto_8bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Flip image if image is backwards\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nd2_file \u001b[38;5;129;01min\u001b[39;00m backward_files:\n",
      "File \u001b[0;32m~/Lab Analysis MAC/ImageAnalysis/Tusc5ImageUtils.py:170\u001b[0m, in \u001b[0;36mto_8bit\u001b[0;34m(image, do_scaling)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_val \u001b[38;5;241m>\u001b[39m min_val:\n\u001b[1;32m    169\u001b[0m     scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255.0\u001b[39m \u001b[38;5;241m/\u001b[39m (max_val \u001b[38;5;241m-\u001b[39m min_val)\n\u001b[0;32m--> 170\u001b[0m     output_image \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# If the image has a single value, map it to 0 or 255\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     output_image\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m min_val \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:161\u001b[0m, in \u001b[0;36m_clip\u001b[0;34m(a, min, max, out, casting, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _clip_dep_invoke_with_casting(\n\u001b[1;32m    159\u001b[0m         um\u001b[38;5;241m.\u001b[39mmaximum, a, \u001b[38;5;28mmin\u001b[39m, out\u001b[38;5;241m=\u001b[39mout, casting\u001b[38;5;241m=\u001b[39mcasting, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clip_dep_invoke_with_casting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:115\u001b[0m, in \u001b[0;36m_clip_dep_invoke_with_casting\u001b[0;34m(ufunc, out, casting, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# try to deal with broken casting rules\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _exceptions\u001b[38;5;241m.\u001b[39m_UFuncOutputCastingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Numpy 1.17.0, 2019-02-24\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting the output of clip from \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass `casting=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m` explicitly to silence this warning, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Code to set min and max for DAPI max projections\n",
    "\n",
    "Automatically records min and max presets in file_mp_configurations.csv\n",
    "If min and max were set multiple times, the most recent parameters are used\n",
    "'''\n",
    "\n",
    "if not parent_directory or not target_folder_name:\n",
    "    raise ValueError('Make sure to input target folder name and parent directory.')\n",
    "\n",
    "mp_configs_df = pd.read_csv('file_mp_configurations.csv')\n",
    "\n",
    "\n",
    "target_folder_path = os.path.join(parent_directory, target_folder_name)\n",
    "nd2_files = [f for f in os.listdir(target_folder_path) if f.endswith('.nd2')]\n",
    "\n",
    "for nd2_file in nd2_files:\n",
    "\n",
    "    # 1) Download Image Data\n",
    "    print(f'Processing {nd2_file}')\n",
    "    nd2_path = os.path.join(target_folder_path, nd2_file)\n",
    "\n",
    "    f = nd2.ND2File(nd2_path)\n",
    "    z_sep = f.voxel_size().z\n",
    "    image = to_8bit(f.asarray())\n",
    "\n",
    "    # Flip image if image is backwards\n",
    "    if nd2_file in backward_files:\n",
    "        image = np.flip(image, axis=0)\n",
    "\n",
    "    # 2) DAPI max projection, Deblur, Segment\n",
    "    DAPI_stack = image[:, 0, :, :].copy()\n",
    "\n",
    "    z0, z1 = run_max_projector_app(DAPI_stack)\n",
    "    mp_config = pd.DataFrame({\n",
    "        'file_name': [nd2_file],\n",
    "        'z0': [z0],\n",
    "        'z1': [z1],\n",
    "        'date': [datetime.now().strftime(\"%H:%M_%d_%m_%Y\")]\n",
    "    })\n",
    "    mp_config.to_csv('file_mp_configurations.csv', mode='a', header=not pd.io.common.file_exists('file_mp_configurations.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Traces\n",
    "\n",
    "- This step takes a folder containing `.nd2` files and returns a DataFrame of traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3608R_GLUT1_WGA_0002.nd2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sl/syqsj8q94yn7kbv8l50mtwdw0000gn/T/ipykernel_12103/148859537.py:32: UserWarning: ND2File file not closed before garbage collection. Please use `with ND2File(...):` context or call `.close()`.\n",
      "  f = nd2.ND2File(nd2_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Masks found: 82/88\n",
      "Processing 3608R_GLUT1_WGA_0001.nd2\n",
      "- Masks found: 85/93\n",
      "Processing 3655R_GLUT1_WGA_0001.nd2\n",
      "- Masks found: 69/133\n",
      "Processing 3607R_GLUT1_WGA_0003.nd2\n",
      "- Masks found: 6/83\n",
      "Processing 3607R_GLUT1_WGA_0002.nd2\n",
      "- Masks found: 9/66\n",
      "Processing 3657R_GLUT1_WGA_0001.nd2\n",
      "- Masks found: 94/113\n",
      "Processing 3606R_GLUT1_WGA_0001.nd2\n",
      "- Masks found: 84/113\n",
      "Processing 3607R_GLUT1_WGA_0001.nd2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Masks found: 22/88\n",
      "Processing 3653L_GLUT1_WGA_0003.nd2\n",
      "- Masks found: 90/126\n",
      "Processing 3653L_GLUT1_WGA_0002.nd2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Masks found: 86/112\n",
      "Processing 3653L_GLUT1_WGA_0001.nd2\n",
      "- Masks found: 55/104\n",
      "Processing 3653L_GLUT1_WGA_0005.nd2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Masks found: 61/94\n",
      "Processing 3653L_GLUT1_WGA_0004.nd2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Masks found: 39/106\n"
     ]
    }
   ],
   "source": [
    "### Setting paths ###\n",
    "if not parent_directory or not target_folder_name:\n",
    "    raise ValueError('Make sure to input target folder name and parent directory.')\n",
    "\n",
    "target_folder_path = os.path.join(parent_directory, target_folder_name)\n",
    "\n",
    "\n",
    "nd2_files = [f for f in os.listdir(target_folder_path) if f.endswith('.nd2')]\n",
    "\n",
    "### Models ###\n",
    "# Setting path for models\n",
    "model_path_dapi = os.path.join(parent_directory, 'ImageAnalysis/cellpose_models/T5_DAPI_V4')\n",
    "model_path_wga = os.path.join(parent_directory, 'ImageAnalysis/cellpose_models/T5_WGA_V2')\n",
    "\n",
    "# Seting the DAPI (deblur) and WGA models\n",
    "deblur_model = denoise.CellposeDenoiseModel(gpu=True, model_type= model_path_dapi, restore_type=\"deblur_cyto3\")\n",
    "wga_model = models.CellposeModel(gpu=True, pretrained_model=model_path_wga)\n",
    "\n",
    "### Reading respective DAPI min and max each respective image stack ###\n",
    "mp_configs_df = pd.read_csv('file_mp_configurations.csv')\n",
    "\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "unid_counter = 0\n",
    "\n",
    "for nd2_file in nd2_files:\n",
    "\n",
    "    # 1) Download Image Data\n",
    "    print(f'Processing {nd2_file}')\n",
    "    nd2_path = os.path.join(target_folder_path, nd2_file)\n",
    "\n",
    "    f = nd2.ND2File(nd2_path)\n",
    "    z_sep = f.voxel_size().z\n",
    "    image = to_8bit(f.asarray())\n",
    "    f.close()\n",
    "\n",
    "    # Flip image if image is backwards\n",
    "    if nd2_file in backward_files:\n",
    "        image = np.flip(image, axis=0)\n",
    "\n",
    "    # 2) DAPI max projection, Deblur, Segment\n",
    "    DAPI_stack = image[:, 0, :, :].copy()\n",
    "\n",
    "    if nd2_file in mp_configs_df['file_name'].values:\n",
    "        file_mp_df = mp_configs_df.loc[mp_configs_df['file_name'] == nd2_file].iloc[-1]\n",
    "        \n",
    "        z0, z1 = file_mp_df['z0'], file_mp_df['z1']\n",
    "\n",
    "\n",
    "    else:\n",
    "        z0, z1 = run_max_projector_app(DAPI_stack)\n",
    "        mp_config = pd.DataFrame({\n",
    "            'file_name': [nd2_file],\n",
    "            'z0': [z0],\n",
    "            'z1': [z1],\n",
    "            'date': [datetime.now().strftime(\"%H:%M_%d_%m_%Y\")]\n",
    "        })\n",
    "        mp_config.to_csv('file_mp_configurations.csv', mode='a', header=not pd.io.common.file_exists('file_mp_configurations.csv'), index=False)\n",
    "\n",
    "\n",
    "    mp_DAPI = max_proj(DAPI_stack[z0:z1].copy())\n",
    "\n",
    "    # 3) Deblur and Segment DAPI max projection\n",
    "    DAPI_masks, flows, styles, image_deblurred = deblur_model.eval(auto_brightness_contrast(mp_DAPI), diameter=None, channels=[0, 0])\n",
    "    image_deblurred = image_deblurred[:, :, 0]  # resulting image has one channel, but it still needs to be indexed\n",
    "\n",
    "\n",
    "    # DAPI filtering and eGFP identification\n",
    "    coords_3d = nuclei_centers_of_mass(DAPI_stack, DAPI_masks)\n",
    "    filtered_coords_3d, filtered_idxs = remove_outliers_local(coords_3d, num_closest_points=15, z_threshold=2)\n",
    "    filtered_DAPI_masks = extract_masks(DAPI_masks, filtered_idxs)\n",
    "    DAPI_masks = filtered_DAPI_masks.copy()\n",
    "\n",
    "    ## Quick view\n",
    "    ## plt.imshow(plot.mask_overlay(to_8bit(image_deblurred), DAPI_masks))\n",
    "    ## plt.axis('off')\n",
    "    ## plt.show()\n",
    "\n",
    "    #Identifying cells in rip\n",
    "    ##coords_2d = [(i[0], i[1]) for i in filtered_coords_3d]\n",
    "    ##in_rip_dict = rip_identifier(nd2_file, image, DAPI_masks, coords_2d)\n",
    "\n",
    "    # List for eGFP identification later\n",
    "    eGFP_fluorescence_list = []\n",
    "    \n",
    "    # Initialize a list to accumulate cell data\n",
    "    file_data_list = []\n",
    "\n",
    "    '''\n",
    "    Indiviudal Cell\n",
    "    '''\n",
    "\n",
    "    # 5) Segmentation of WGA channel\n",
    "    mask_idxs = np.delete(np.unique(DAPI_masks), 0) - 1\n",
    "\n",
    "    total_masks = len(mask_idxs)  # Total number of masks to process\n",
    "    masks_found = 0  # Counter for the number of masks found\n",
    "\n",
    "    for mask_id in mask_idxs:\n",
    "\n",
    "        single_mask = extract_masks(DAPI_masks, mask_id)\n",
    "        diam = get_mask_diameter(single_mask)\n",
    "        expansion = 50\n",
    "\n",
    "        sq_stacks = get_sq_stacks(image, single_mask)\n",
    "\n",
    "        # Running the model of the expanded squares\n",
    "        expanded_sq_WGA, z_level = extract_square_proj_expand(image, single_mask, expansion)\n",
    "\n",
    "        expanded_mask, flows, styles = wga_model.eval(expanded_sq_WGA, diameter=diam, channels=[0, 0])\n",
    "\n",
    "        # Removing 0-pixel boundary and finding the largest mask in the array\n",
    "        WGA_mask = remove_boundary(expanded_mask, expansion)\n",
    "\n",
    "        if len(np.unique(WGA_mask)) == 1:\n",
    "            continue\n",
    "\n",
    "        elif len(np.unique(WGA_mask)) > 2:\n",
    "            WGA_mask = closest_mask_2d(single_mask, WGA_mask)\n",
    "\n",
    "        masks_found += 1  # Increment the masks found counter\n",
    "\n",
    "        # Z-axis profile\n",
    "        trace_results = get_traces(sq_stacks, WGA_mask)\n",
    "\n",
    "        # eGFP extraction\n",
    "        eGFP_sum = np.sum(sq_stacks[1, z_level, :, :][(WGA_mask.astype(bool))])\n",
    "        eGFP_sum_per_area = eGFP_sum / np.sum(WGA_mask)\n",
    "\n",
    "        eGFP_fluorescence_list.append((mask_id, eGFP_sum_per_area))\n",
    "\n",
    "        '''\n",
    "        Organizing data\n",
    "        '''\n",
    "\n",
    "        # 6) Converting trace results into a pd dataframe\n",
    "        cell_data = organize_data(trace_results, mask_id)\n",
    "\n",
    "        # 7) Adding file information\n",
    "        djid, eye, file_base = extract_information(nd2_file)\n",
    "\n",
    "        nested_array = np.array(range(image.shape[0])) * z_sep\n",
    "        cell_data['X_vals'] = [nested_array for i in range(len(cell_data))]\n",
    "        cell_data['file_name'] = file_base\n",
    "        cell_data['DJID'] = djid\n",
    "        cell_data['Eye'] = eye\n",
    "        cell_data['eGFP_Value'] = False\n",
    "        cell_data['eGFP_Raw_Intensity'] = eGFP_sum_per_area\n",
    "\n",
    "        # Adding in_rip information\n",
    "        cell_data['in_rip'] = False\n",
    "\n",
    "        ##for file_name, mask_ids in in_rip_dict.items():\n",
    "        ##    if file_name == file_base and mask_id in mask_ids:\n",
    "        ##        cell_data['in_rip'] = True\n",
    "\n",
    "        # Accumulating cell data\n",
    "        file_data_list.append(cell_data)\n",
    "\n",
    "    # Print the number of masks found out of the total possible masks\n",
    "    print(f'- Masks found: {masks_found}/{total_masks}')\n",
    "\n",
    "    # Concatenating the list into a single DataFrame for the file\n",
    "    file_data = pd.concat(file_data_list, ignore_index=True)\n",
    "\n",
    "    # Processing eGFP data for the entire file\n",
    "    eGFP_idxs = np.array([i[0] for i in eGFP_fluorescence_list])\n",
    "    eGFP_vals = np.array([i[1] for i in eGFP_fluorescence_list])\n",
    "\n",
    "    # Normalizing eGFP values\n",
    "    eGFP_vals_normal = normalize(eGFP_vals)\n",
    "\n",
    "    # Setting cells above .2 as positive\n",
    "    eGFP_pos_idxs = eGFP_idxs[eGFP_vals_normal > .2]\n",
    "    file_data.loc[file_data['mask_id'].isin(eGFP_pos_idxs), 'eGFP_Value'] = True\n",
    "\n",
    "    # Accumulating data at the all_data level\n",
    "    all_data = pd.concat([all_data, file_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = all_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for quick examination of any single cell\n",
    "##export_df_temp = export_df.copy()\n",
    "##export_df_temp['Cell_unid'] = export_df.groupby(['file_name', 'mask_id']).ngroup()\n",
    "##plot_single_cell(export_df_temp.query('Cell_unid == 10'), prominence =15, distance = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df['X_vals'] = export_df['X_vals'].apply(lambda x: ', '.join(map(str, x)))\n",
    "export_df['Y_vals'] = export_df['Y_vals'].apply(lambda x: ', '.join(map(str, x)))\n",
    "export_df = export_df.loc[export_df['file_name'] != '3607R_GLUT1_WGA_0001']\n",
    "\n",
    "### VVV ATTENTION VVV\n",
    "\n",
    "raw_data_csv_name = #INPUT\n",
    "export_df.to_csv('raw_data_folder/' + raw_data_csv_name + '.csv', index = False) # Carefully modify export csv name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
